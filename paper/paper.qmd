---
title: "Predicting the 2024 US Presidential Election: A Polling-Based Forecast"
subtitle: "Utilizing Statistical Models to Assess Donald Trump's Support"
author: 
  - Tianrui Fu
  - Yiyue Deng
  - Jianing Li
thanks: "Code and data are available at: [https://github.com/RohanAlexander/starter_folder](https://github.com/RohanAlexander/starter_folder). and [https://projects.fivethirtyeight.com/polls/president-general/2024/national/](https://projects.fivethirtyeight.com/polls/president-general/2024/national/)"
date: today
date-format: long
abstract: "This paper uses polling data to predict the outcome of the 2024 U.S. presidential election. By applying generalized linear regression and Bayesian models, we analyze the factors related to the polls, including polling organizations and the ratings associated with those organizations, on Donald Trump’s support rate. The research results indicate a significant relationship between the variables, with Donald Trump’s support rate showing an upward trend. Additionally, we further discuss the advantages and disadvantages of the two models, as well as potential methods for improvement."
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(arrow)
library(kableExtra)
library(ggplot2)
library(dplyr)
library(rstanarm)
library(modelsummary)
library(modelr)
```


# Introduction {#sec-data}

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....






# Data {#sec-data}

## Overview

We use the statistical programming language @citeR, the templete from @citeRohan completed by following packages：tidyverse @tidyverse, dplyr @dplyr, rstanarm @rstanarm, arrow @arrow, modelr @modelr, modelsummary @modelsummary, ggplot2 @ggplot2, here @citehere, kableExtra @kableExtra and knitr @citeknitr to complete this analysis. Our data about the latest polling outcomes is from the website @fivethirtyeight2024. It has 52 variables and 15891 observations in this data set, including pollster, poll score, etc.
```{r, fig.pos= 'H', fig.width=8, fig.height=4}
#| label: tbl-dataset-example
#| tbl-cap: The example of chosen variable datset
#| echo: false
set.seed(123)
analysis_data <- read_parquet(here::here("data/02-analysis_data/analysis_data.parquet"))
example_dataset <- analysis_data[sample(1:nrow(analysis_data), 10), c("pollster", "pollscore", "numeric_grade", "transparency_score", "end_date", "pct")]
kable(example_dataset, col.names = c("pollster", "pollscore", "numeric_grade", "transparency_score", "end_date", "pct")) %>%
  kable_styling() %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(0, extra_css = "border-bottom: 2px solid black;")  
```

## Cleaning Data
We have cleaned the data set and the detailed procedure see from the appendix.

## Measurement
	
After cleaning the data set, we have get about 38 variables and 492 observations about the polling outcomes for Donald Trump. In order to analysis if the different pollster can influence the final result of U.S. president election, we choose some related variable to build the Bayesian model. The related variables has the numeric grade, transparency score, poll score, pollster, the end date and percentage. The explain of each used variable please see in the @sec-cleandata.

## Outcome variables
The @fig-percentage-pollster shows the distribution of polling data over time, with each color representing a different polling organization. We can see that as time progresses from August to October, there is a steady increase in the amount of polling data, peaking around early October. This suggests that multiple organizations have contributed to polling data on a consistent basis over this period.

In the @fig-pct-density, it reveals a central peak around the 45-50% range, indicating that most of the values for this variable are concentrated in this area. The shape of the plot suggests a right-skewed distribution, with relatively few data points falling below 40% or above 50%. This gives an overview of the central tendency and variability of the polling percentages.

```{r, fig.pos= 'H', fig.width=8, fig.height=4}
#| label: fig-percentage-pollster
#| fig-cap: Percentage of Each Pollster Over Time
#| echo: false
ggplot(analysis_data, aes(x = end_date, y = pct, fill = pollster)) +
  geom_area(position = "stack", alpha = 0.7) +
  labs(x = "End Date", y = "Percentage (%)") +
  theme_minimal()
```

```{r, fig.pos= 'H', fig.width=8, fig.height=4}
#| label: fig-pct-density
#| fig-cap: Density plot of pct
#| echo: false
ggplot(analysis_data, aes(x = pct)) +
  geom_density(fill = "lightblue", color = "blue", alpha = 0.5) +
  labs(title = "Density Plot of Pct", x = "Pct", y = "Density") +
  theme_minimal()
```
## Predictor variables

In @fig-frequency-bar, the predictor variable is the count of polls conducted by each pollster. The bar chart displays the number of polls released by different polling organizations, ordered from highest to lowest frequency. The bars range in color from light blue to dark blue, indicating the frequency of polls conducted by each organization. Siena/NYT and YouGov are the most active pollsters, with 94 and 59 polls conducted, respectively. Emerson and Beacon/Shaw also have high polling frequencies, with 58 and 46 polls. In contrast, several pollsters, like Christopher Newport University and Data Orbital, conducted only one poll, indicating their minimal activity in comparison.

```{r, fig.pos= 'H', fig.width=8, fig.height=4}
#| label: fig-frequency-bar
#| fig-cap: Frequency of each pollster
#| echo: false
ggplot(analysis_data, aes(y = reorder(pollster, table(pollster)[pollster]))) +  
  geom_bar(aes(fill = after_stat(count)), color = "black") +                          
  geom_text(stat = "count", aes(label = after_stat(count)), hjust = -0.1, size = 2) +  
  scale_fill_gradient(low = "lightblue", high = "blue") +
  labs(x = "Count", y = "Pollster") +       
  theme_minimal() +
  theme(axis.text.x = element_text(size = 8)) 
```
In @fig-avg-pollscore, the predictor variable is the average poll score for each pollster over time, from August to October. This heat map visualizes the poll scores of each organization on different dates, with color intensity indicating the score levels—darker colors represent lower scores. The pollsters with the most consistently low average poll scores (darker colors) include Selzer, Siena/NYT, and Marquette Law School. These pollsters frequently show results lower than others over time, suggesting they may consistently lean toward one direction in their results. In contrast, pollsters like YouGov Center for Working Class Politics and YouGov Blue display lighter colors, indicating relatively higher scores across their polls.
```{r, fig.pos= 'H', fig.width=8, fig.height=4}
#| label: fig-avg-pollscore
#| fig-cap: Average Pollscore by Pollster and End Date
#| echo: false
library(dplyr)

heatmap_data <- analysis_data %>%
  group_by(pollster, end_date) %>%
  summarise(mean_pollscore = mean(pollscore, na.rm = TRUE), .groups = "drop") 

ggplot(heatmap_data, aes(x = end_date, y = pollster, fill = mean_pollscore)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(x = "End Date", y = "Pollster", fill = "Avg Pollscore") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(size = 8))
  
```
In @fig-plot, there is a clear positive relationship between transparency score and numeric grade. Pollsters with higher transparency scores, such as those scoring around 10, tend to achieve higher numeric grades, close to 3.0. Conversely, pollsters with lower transparency scores tend to have lower numeric grades, closer to 2.7. This pattern suggests that greater transparency is associated with better overall pollster ratings.
```{r, fig.pos= 'H', fig.width=8, fig.height=4}
#| label: fig-plot
#| fig-cap: Scatter Plot of transparency score and numeric grade
#| echo: false
#| message: false
#| warning: false
suppressWarnings({
  ggplot(analysis_data, aes(x = transparency_score, y = numeric_grade)) +
    geom_point(color = "darkblue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(x = "Transparency Score", y = "Numeric Grade") +
    theme_minimal()
})
```

# Model {#sec-data}

The goal of our modeling strategy is twofold. Firstly, we aim to estimate the impact of key factors—such as pollster reliability scores, transparency, and specific pollster effects—on polling results. Secondly, we seek to analyze how these effects change over time. Here, we briefly describe the Bayesian analysis model used to investigate these relationships.
Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up
In this Bayesian framework, we assume a normal distribution of poll results around a mean affected by key predictors: numeric grade, transparency score, and pollscore. Define $y_i$ as the percentage. Then $\beta_i$ represents the numeric grade, $\gamma_i$ represents the transparency score, and $\delta_i$ represents the pollscore.

\begin{align}
y_i|\mu_i, \sigma &\sim \text{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \cdot \text{numeric\_grade}_i + \beta_2 \cdot \text{transparency\_score}_i + \beta_3 \cdot \text{pollscore}_i \\
&\quad + \sum_{j=1}^{N} \gamma_j \cdot \text{pollster}_j + \delta_i \cdot \text{end\_date}_i \\
\alpha &\sim \text{Normal}(50, 10) \\
\beta_1, \beta_2, \beta_3 &\sim \text{Normal}(0, 5) \\
\gamma_j &\sim \text{Normal}(0, 5) \\
\sigma &\sim \text{Exponential}(1)
\end{align}
where the intercept $\alpha$ represents an average poll result, and each $\beta$ coefficient captures the unique effect of its respective predictor on the poll percentage. The variable 
$ pollster_j $ denotes a specific pollster effect, while $ end date_i $ accounts for time trends. Priors are applied as follows: $\alpha$ follows a normal distribution centered at 50 with a standard deviation of 10, and each $\beta$ and $\gamma$ parameter is set to a normal prior of mean 0 and standard deviation 5, reflecting mild assumptions about effect direction without biasing their magnitude. Finally, the noise parameter $\sigma$ follows an exponential distribution with rate 1, allowing flexibility in unexplained variation. We run the model in @citeR using the package of @rstanarm.

### Model justification

This model balances complexity with interpretability, accounting for factors like numeric grades and transparency scores while maintaining computational simplicity. Predictors such as pollscore and transparency score were chosen based on their significance in the data section, reflecting reliability and potential biases. Including individual pollster effects as fixed coefficients captures potential pollster-specific deviations, while end date trends allow us to observe temporal shifts in poll support. This structure is intended to balance explanatory power with generalizability.

# Results {#sec-data}

Our results are summarized in @tbl-modelresults and the plot for glm and bayesian is in @fig-final and @fig-bayes respectively.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)
library(here)

model_final_glm <-
  readRDS(file = here::here("models/model_final.rds"))
model_bayes <-
  readRDS(file = here::here("models/model_bayes.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false
library(modelsummary)
library(kableExtra)
library(dplyr)
coef_names <- c("end_date" = "End Date",
                "pollsterBeacon/Shaw" = "Beacon/Shaw",
                "pollsterChristopher Newport U." = "Christopher Newport U.",
                "pollsterCNN/SSRS" = "CNN/SSRS",
                "pollsterData Orbital" = "Data Orbital",
                "pollsterEchelon Insights" = "Echelon Insights",
                "pollsterEmerson" = "Emerson",
                "pollsterIpsos" = "Ipsos",
                "pollsterMarist" = "Marist",
                "pollsterMarquette Law School" = "Marquette Law School",
                "pollsterMassINC Polling Group" = "MassINC Polling Group",
                "pollsterMcCourtney Institute/YouGov" = "McCourtney Institute/YouGov",
                "pollsterMuhlenberg" = "Muhlenberg",
                "pollsterQuinnipiac" = "Quinnipiac",
                "pollsterSelzer" = "Selzer",
                "pollsterSiena" = "Siena",
                "pollsterSiena/NYT" = "Siena/NYT",
                "pollsterSuffolk" = "Suffolk",
                "pollsterSurveyUSA" = "SurveyUSA",
                "pollsterSurveyUSA/High Point University" = "SurveyUSA/High Point University",
                "pollsterThe Washington Post" = "The Washington Post",
                "pollsterU. North Florida" = "U. North Florida",
                "pollsterUniversity of Massachusetts Lowell/YouGov" = "University of Massachusetts Lowell/YouGov",
                "pollsterWashington Post/George Mason University" = "Washington Post/George Mason University",
                "pollsterYouGov" = "YouGov",
                "pollsterYouGov Blue" = "YouGov Blue",
                "pollsterYouGov/Center for Working Class Politics" = "YouGov/Center for Working Class Politics")
                
modelsummary(models = list("Model by glm" = model_final_glm, 
                           "Model by bayes" = model_bayes),
             statistic = "conf.int",
             conf_level = 0.95,
             stars = TRUE,
             coef_rename = coef_names,
             output = "kableExtra") %>%
  kable_styling(full_width = F, position = "left", bootstrap_options = c("striped", "hover"
                                                                           , line_height = 6)) %>%
  column_spec(column = 2, width = "2em") %>%
  column_spec(column = 2, width = "4em") %>%
  add_header_above(c(" " = 1, "Model Summary" = 2)) %>%
  kable_classic(full_width = F, font_size = 4) %>%
  add_footnote("This table shows the regression models with custom variable names.")

```

```{r}
#| echo: false
#| eval: true
#| label: fig-final
#| fig-cap: GLM with pollster, related variable and date
#| warning: false
#| message: false
library(modelsummary)
library(modelr)
analysis_data <- analysis_data |>
  add_predictions(model_final_glm, var = "final")

ggplot(analysis_data, aes(x = end_date)) +
  geom_point(aes(y = pct), color = "black") +
  geom_smooth(aes(y = final), color = "red", linetype = "dotted") +
  theme_classic() +
  labs(y = "Trump Percent", x = "Date")
```

```{r, fig.pos= 'H', fig.width=10, fig.height=6}
#| echo: false
#| eval: true
#| label: fig-bayes
#| fig-cap: Poll Percentage over Time with Bayesian Fit
#| warning: false

new_data <- data.frame(
  end_date = seq(
    min(analysis_data$end_date),
    max(analysis_data$end_date),
    length.out = 100
  ),
  numeric_grade = mean(analysis_data$numeric_grade),
  pollscore = mean(analysis_data$pollscore),
  transparency_score = mean(analysis_data$transparency_score),
  pollster = factor("AtlasIntel")
)

posterior_preds <- posterior_predict(model_bayes, newdata = new_data)


pred_summary <- new_data |>
  mutate(
    pred_mean = colMeans(posterior_preds),
    pred_lower = apply(posterior_preds, 2, quantile, probs = 0.025),
    pred_upper = apply(posterior_preds, 2, quantile, probs = 0.975)
  )


ggplot(analysis_data, aes(x = end_date, y = pct, color = pollster)) +
  geom_point() +
  geom_line(
    data = pred_summary,
    aes(x = end_date, y = pred_mean),
    color = "blue",
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = pred_summary,
    aes(x = end_date, ymin = pred_lower, ymax = pred_upper),
    alpha = 0.2,
    inherit.aes = FALSE
  ) +
  labs(
    x = "End Date",
    y = "Percentage"
  ) +
  theme_minimal() +
  theme(
    legend.key.size = unit(1, "cm"),
    legend.text = element_text(size = 5) 
  )
```


# Discussion {#sec-data}

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {#sec-data}

## Clean data {#sec-cleandata}

It starts by reading the dataset and standardizing column names. Next, it removes irrelevant columns like sponsor_ids, sponsors, and etc and filters for high-quality polls (with a rating of 2.7 or higher) that specifically track Trump’s support. National polls missing state information are labeled as "National," and dates are formatted and filtered to include only those on or after July 21, 2024 (when Trump declared his candidacy). Finally, the percentage supporting Trump is converted to an actual count for further modeling.

## Variable details

We have used the variable numeric_grade, transparency_score, pollster, poll score, end_date and pct in the building of Bayesian model. Among these variables in the data set after analysis, the numeric_grade is the numeric rating given to the pollster to indicate their quality or reliability from 2.7 to 3.0. The transparency_score is the grade for how transparent a pollster is, calculated based on how much information it discloses about its polls and weighted by recency from 4.5 to 10.0. The pollster is the name of the polling organization that conducted the poll included Marquette Law School, CNN/SSRS and etc. The poll score is the numeric value representing the score or reliability of the pollster in question from -1.5 to -0.5 and negative numbers of poll score are better. The end_date is the date of polling ends. The pct is the percentage of the vote or support that the candidate received in the poll and keep integer.

## Survey

We have made a survey for this task with the link: [https://docs.google.com/forms/d/1waQdvN-7UpkHuRuMqqC4tbzqNaqD6A_4DIQ8itGjmxI/edit](https://docs.google.com/forms/d/1waQdvN-7UpkHuRuMqqC4tbzqNaqD6A_4DIQ8itGjmxI/edit) and the following is the copy of survey. 
2024 United States Presidential Election Survey
Introduction:
Thank you for taking part in our survey on the 2024 United States Presidential Election. Your input will help us understand voters’ views on candidates and key policy issues. All responses are confidential and will be used solely for statistical purposes. As a token of appreciation, participants will have a chance to win a small reward, with one in every 100 respondents receiving $5 to $10.

For Questions or Concerns, Please Contact:

Tianrui Fu
Email: tianrui.fu@mail.utoronto.ca

Jianing Li
Email: lijianing.li@mail.utoronto.ca

Yiyue Deng
Email: yiyue.deng@mail.utoronto.ca

What is your age?

18-29
30-44
45-64
65 and above

What is your gender?

Male
Female
Other
Prefer not to say

What is your highest level of education?

High school or below
Bachelor’s degree
Master’s degree or above

Which state do you currently reside in? 

Choose one state in the list

Do you plan to vote in the 2024 election?

Yes
No
Not sure

If the election were held today, which candidate would you be more likely to support?

Kamala Harris (Democratic Party)
Donald Trump (Republican Party)
Other
Undecided

Which of the following issues would have the greatest impact on your decision in the 2024 election? (Select one)

Economic stability and growth
Access to quality healthcare
Education reform and funding
Addressing social and racial inequalities

Other:

If a future candidate proposed a policy that aligns perfectly with your concerns, would you consider changing your voting intention?

Yes
No
Not sure

If you would like to participate in the reward draw, please provide your email address below. Your contact information will only be used to notify winners. We will reach out to winners via email.


# Additional data details

# Model details {#sec-model-details}

To maintain readability while demonstrating model robustness, we include the following in the appendix:

- **Prior Justification and Sensitivity Analyses:** Alternative priors and their justifications are provided, alongside a sensitivity analysis to examine the impact of these priors on the posterior distributions.

- **Model Validation and Out-of-Sample Testing:** Validation metrics, such as RMSE calculations, out-of-sample testing, and test-train splits, offer evidence of the model’s predictive accuracy, complementing in-sample performance.

- **Alternative Models and Comparison:** An analysis of simpler and more complex models is included, explaining the rationale for selecting this Bayesian model based on performance metrics and interpretability.

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]


```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

```



\newpage


# References


