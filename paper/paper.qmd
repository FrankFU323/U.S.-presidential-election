---
title: "Predicting the 2024 US Presidential Election: A Polling-Based Forecast"
subtitle: "My subtitle if needed"
author: 
  - Tianrui Fu
  - Yiyue Deng
thanks: "Code and data are available at: [https://github.com/RohanAlexander/starter_folder](https://github.com/RohanAlexander/starter_folder)."
date: today
date-format: long
abstract: "This paper forecasts the 2024 US Presidential election outcome using polling data from [insert pollster name]. By applying simple and multiple linear regression models, we analyze the effect of polling factors, including sample size, poll score, and transparency, on support percentages for key candidates. Our findings suggest significant relationships between these variables, providing an evidence-based approach to predicting election outcomes. We further explore methodological strengths and weaknesses and propose an ideal polling survey methodology. This work highlights the potential for data-driven insights into political forecasting."
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(arrow)
library(kableExtra)
library(ggplot2)
library(dplyr)
library(rstanarm)
library(modelsummary)
```


# Introduction {#sec-data}

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....






# Data {#sec-data}

## Overview

We use the statistical programming language @citeR to complete this analysis. Our data about the latest polling outcomes is from the website[@]. It has 52 variables and 15891 observations in this data set, including pollster, poll score, etc.

```{r, fig.pos= 'H', fig.width=8, fig.height=4}
#| label: tbl-dataset-example
#| tbl-cap: The example of chosen variable datset
#| echo: false
set.seed(123)
analysis_data <- read_parquet(here::here("data/02-analysis_data/analysis_data.parquet"))
example_dataset <- analysis_data[sample(1:nrow(analysis_data), 10), c("pollster", "pollscore", "numeric_grade", "transparency_score", "end_date", "pct")]
kable(example_dataset, col.names = c("pollster", "pollscore", "numeric_grade", "transparency_score", "end_date", "pct")) %>%
  kable_styling() %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(0, extra_css = "border-bottom: 2px solid black;")  
```

## Cleaning Data
We have cleaned the data set and the detailed procedure see from the appendix.

## Measurement
	
After cleaning the data set, we have get about 38 variables and 492 observations about the polling outcomes for Donald Trump. In order to analysis if the different pollster can influence the final result of U.S. president election, we choose some related variable to build the Bayesian model. The related variables has the numeric grade, transparency score, poll score, pollster, the end date and percentage. The explain of each used variable please see in the @appendix-variable.

## Outcome variables
The @fig-percentage-pollster shows the distribution of polling data over time, with each color representing a different polling organization. We can see that as time progresses from August to October, there is a steady increase in the amount of polling data, peaking around early October. This suggests that multiple organizations have contributed to polling data on a consistent basis over this period.

In the @fig-pct-density, it reveals a central peak around the 45-50% range, indicating that most of the values for this variable are concentrated in this area. The shape of the plot suggests a right-skewed distribution, with relatively few data points falling below 40% or above 50%. This gives an overview of the central tendency and variability of the polling percentages.

```{r, fig.pos= 'H', fig.width=8, fig.height=4}
#| label: fig-percentage-pollster
#| fig-cap: Percentage of Each Pollster Over Time
#| echo: false
ggplot(analysis_data, aes(x = end_date, y = pct, fill = pollster)) +
  geom_area(position = "stack", alpha = 0.7) +
  labs(x = "End Date", y = "Percentage (%)") +
  theme_minimal()
```

```{r, fig.pos= 'H', fig.width=8, fig.height=4}
#| label: fig-pct-density
#| fig-cap: Density plot of pct
#| echo: false
ggplot(analysis_data, aes(x = pct)) +
  geom_density(fill = "lightblue", color = "blue", alpha = 0.5) +
  labs(title = "Density Plot of Pct", x = "Pct", y = "Density") +
  theme_minimal()
```
## Predictor variables

In @fig-frequency-bar, the predictor variable is the count of polls conducted by each pollster. The bar chart displays the number of polls released by different polling organizations, ordered from highest to lowest frequency. The bars range in color from light blue to dark blue, indicating the frequency of polls conducted by each organization. Siena/NYT and YouGov are the most active pollsters, with 94 and 59 polls conducted, respectively. Emerson and Beacon/Shaw also have high polling frequencies, with 58 and 46 polls. In contrast, several pollsters, like Christopher Newport University and Data Orbital, conducted only one poll, indicating their minimal activity in comparison.

```{r, fig.pos= 'H', fig.width=8, fig.height=4}
#| label: fig-frequency-bar
#| fig-cap: Frequency of each pollster
#| echo: false
ggplot(analysis_data, aes(y = reorder(pollster, table(pollster)[pollster]))) +  
  geom_bar(aes(fill = after_stat(count)), color = "black") +                          
  geom_text(stat = "count", aes(label = after_stat(count)), hjust = -0.1, size = 2) +  
  scale_fill_gradient(low = "lightblue", high = "blue") +
  labs(x = "Count", y = "Pollster") +       
  theme_minimal() +
  theme(axis.text.x = element_text(size = 8)) 
```
In @fig-avg-pollscore, the predictor variable is the average poll score for each pollster over time, from August to October. This heat map visualizes the poll scores of each organization on different dates, with color intensity indicating the score levels—darker colors represent lower scores. The pollsters with the most consistently low average poll scores (darker colors) include Selzer, Siena/NYT, and Marquette Law School. These pollsters frequently show results lower than others over time, suggesting they may consistently lean toward one direction in their results. In contrast, pollsters like YouGov Center for Working Class Politics and YouGov Blue display lighter colors, indicating relatively higher scores across their polls.
```{r, fig.pos= 'H', fig.width=8, fig.height=4}
#| label: fig-avg-pollscore
#| fig-cap: Average Pollscore by Pollster and End Date
#| echo: false
library(dplyr)

heatmap_data <- analysis_data %>%
  group_by(pollster, end_date) %>%
  summarise(mean_pollscore = mean(pollscore, na.rm = TRUE), .groups = "drop") 

ggplot(heatmap_data, aes(x = end_date, y = pollster, fill = mean_pollscore)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(x = "End Date", y = "Pollster", fill = "Avg Pollscore") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(size = 8))
  
```
In @fig-plot, there is a clear positive relationship between transparency score and numeric grade. Pollsters with higher transparency scores, such as those scoring around 10, tend to achieve higher numeric grades, close to 3.0. Conversely, pollsters with lower transparency scores tend to have lower numeric grades, closer to 2.7. This pattern suggests that greater transparency is associated with better overall pollster ratings.
```{r, fig.pos= 'H', fig.width=8, fig.height=4}
#| label: fig-plot
#| fig-cap: Scatter Plot of transparency score and numeric grade
#| echo: false
#| message: false
#| warning: false
suppressWarnings({
  ggplot(analysis_data, aes(x = transparency_score, y = numeric_grade)) +
    geom_point(color = "darkblue", alpha = 0.6) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(x = "Transparency Score", y = "Numeric Grade") +
    theme_minimal()
})
```

# Model {#sec-data}

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up
Define $y_i$ as the percentage. Then $\beta_i$ represents the numeric grade, $\gamma_i$ represents the transparency score, and $\delta_i$ represents the pollscore.

\begin{align}
y_i|\mu_i, \sigma &\sim \text{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \cdot \text{numeric\_grade}_i + \beta_2 \cdot \text{transparency\_score}_i + \beta_3 \cdot \text{pollscore}_i \\
&\quad + \sum_{j=1}^{N} \gamma_j \cdot \text{pollster}_j + \delta_i \cdot \text{end\_date}_i \\
\alpha &\sim \text{Normal}(50, 10) \\
\beta_1, \beta_2, \beta_3 &\sim \text{Normal}(0, 5) \\
\gamma_j &\sim \text{Normal}(0, 5) \\
\sigma &\sim \text{Exponential}(1)
\end{align}
We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results {#sec-data}

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)
library(here)

model_final_glm <-
  readRDS(file = here::here("models/model_final.rds"))
model_bayes <-
  readRDS(file = here::here("models/model_bayes.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false
library(modelsummary)
library(kableExtra)
library(dplyr)
coef_names <- c("end_date" = "End Date",
                "pollsterBeacon/Shaw" = "Beacon/Shaw",
                "pollsterChristopher Newport U." = "Christopher Newport U.",
                "pollsterCNN/SSRS" = "CNN/SSRS",
                "pollsterData Orbital" = "Data Orbital",
                "pollsterEchelon Insights" = "Echelon Insights",
                "pollsterEmerson" = "Emerson",
                "pollsterIpsos" = "Ipsos",
                "pollsterMarist" = "Marist",
                "pollsterMarquette Law School" = "Marquette Law School",
                "pollsterMassINC Polling Group" = "MassINC Polling Group",
                "pollsterMcCourtney Institute/YouGov" = "McCourtney Institute/YouGov",
                "pollsterMuhlenberg" = "Muhlenberg",
                "pollsterQuinnipiac" = "Quinnipiac",
                "pollsterSelzer" = "Selzer",
                "pollsterSiena" = "Siena",
                "pollsterSiena/NYT" = "Siena/NYT",
                "pollsterSuffolk" = "Suffolk",
                "pollsterSurveyUSA" = "SurveyUSA",
                "pollsterSurveyUSA/High Point University" = "SurveyUSA/High Point University",
                "pollsterThe Washington Post" = "The Washington Post",
                "pollsterU. North Florida" = "U. North Florida",
                "pollsterUniversity of Massachusetts Lowell/YouGov" = "University of Massachusetts Lowell/YouGov",
                "pollsterWashington Post/George Mason University" = "Washington Post/George Mason University",
                "pollsterYouGov" = "YouGov",
                "pollsterYouGov Blue" = "YouGov Blue",
                "pollsterYouGov/Center for Working Class Politics" = "YouGov/Center for Working Class Politics")
                
modelsummary(models = list("Model by glm" = model_final_glm, 
                           "Model by bayes" = model_bayes),
             statistic = "conf.int",
             conf_level = 0.95,
             stars = TRUE,
             coef_rename = coef_names,
             output = "kableExtra") %>%
  kable_styling(full_width = F, position = "left", bootstrap_options = c("striped", "hover"
                                                                           , line_height = 6)) %>%
  column_spec(column = 2, width = "2em") %>%
  column_spec(column = 2, width = "4em") %>%
  add_header_above(c(" " = 1, "Model Summary" = 2)) %>%
  kable_classic(full_width = F, font_size = 4) %>%
  add_footnote("This table shows the regression models with custom variable names.")

```

```{r}
#| echo: false
#| eval: true
#| label: fig-final
#| fig-cap: ddd
#| warning: false
#| message: false
library(modelsummary)
library(modelr)
analysis_data <- analysis_data |>
  add_predictions(model_final_glm, var = "final")

ggplot(analysis_data, aes(x = end_date)) +
  geom_point(aes(y = pct), color = "black") +
  geom_smooth(aes(y = final), color = "red", linetype = "dotted") +
  theme_classic() +
  labs(y = "Trump Percent", x = "Date", title = "Linear Model: pct ~ end_date + numeric_grade")
```

```{r, fig.pos= 'H', fig.width=10, fig.height=6}
#| echo: false
#| eval: true
#| label: fig-bayes
#| fig-cap: Poll Percentage over Time with Bayesian Fit
#| warning: false

new_data <- data.frame(
  end_date = seq(
    min(analysis_data$end_date),
    max(analysis_data$end_date),
    length.out = 100
  ),
  numeric_grade = mean(analysis_data$numeric_grade),
  pollscore = mean(analysis_data$pollscore),
  transparency_score = mean(analysis_data$transparency_score),
  pollster = factor("AtlasIntel")
)

posterior_preds <- posterior_predict(model_bayes, newdata = new_data)


pred_summary <- new_data |>
  mutate(
    pred_mean = colMeans(posterior_preds),
    pred_lower = apply(posterior_preds, 2, quantile, probs = 0.025),
    pred_upper = apply(posterior_preds, 2, quantile, probs = 0.975)
  )


ggplot(analysis_data, aes(x = end_date, y = pct, color = pollster)) +
  geom_point() +
  geom_line(
    data = pred_summary,
    aes(x = end_date, y = pred_mean),
    color = "blue",
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = pred_summary,
    aes(x = end_date, ymin = pred_lower, ymax = pred_upper),
    alpha = 0.2,
    inherit.aes = FALSE
  ) +
  labs(
    x = "End Date",
    y = "Percentage"
  ) +
  theme_minimal() +
  theme(
    legend.key.size = unit(1, "cm"),  # 图例项的大小
    legend.text = element_text(size = 5)  # 图例文字的大小
  )
```


# Discussion {#sec-data}

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {#sec-data}

## Clean data
It starts by reading the dataset and standardizing column names. Next, it removes irrelevant columns like sponsor_ids, sponsors, and etc and filters for high-quality polls (with a rating of 2.7 or higher) that specifically track Trump’s support. National polls missing state information are labeled as "National," and dates are formatted and filtered to include only those on or after July 21, 2024 (when Trump declared his candidacy). Finally, the percentage supporting Trump is converted to an actual count for further modeling.
## Variable details
We have used the variable numeric_grade, transparency_score, pollster, poll score, end_date and pct in the building of Bayesian model. Among these variables in the data set after analysis, the numeric_grade is the numeric rating given to the pollster to indicate their quality or reliability from 2.7 to 3.0. The transparency_score is the grade for how transparent a pollster is, calculated based on how much information it discloses about its polls and weighted by recency from 4.5 to 10.0. The pollster is the name of the polling organization that conducted the poll included Marquette Law School, CNN/SSRS and etc. The poll score is the numeric value representing the score or reliability of the pollster in question from -1.5 to -0.5 and negative numbers of poll score are better. The end_date is the date of polling ends. The pct is the percentage of the vote or support that the candidate received in the poll and keep integer.

# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]


```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

```



\newpage


# References


